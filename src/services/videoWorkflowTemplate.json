{
  "12": {
    "inputs": {
      "vae_name": "hyvid\\hunyuan_video_vae_bf16.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "13": {
    "inputs": {
      "clip_name1": "clip_l.safetensors",
      "clip_name2": "llava_llama3_fp16.safetensors",
      "type": "hunyuan_video",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "15": {
    "inputs": {
      "conditioning": ["47", 0]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "17": {
    "inputs": {
      "crop": "center",
      "clip_vision": ["18", 0],
      "image": ["48", 0]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "18": {
    "inputs": {
      "clip_name": "sigclip_vision_patch14_384.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "19": {
    "inputs": {
      "image": "IMG_9841.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "20": {
    "inputs": {
      "pixels": ["48", 0],
      "vae": ["12", 0]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "23": {
    "inputs": {
      "frame_rate": 24,
      "loop_count": 0,
      "filename_prefix": "FramePack",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "pingpong": false,
      "save_output": true,
      "images": ["44", 0]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ðŸŽ¥ðŸ…¥ðŸ…—ðŸ…¢"
    }
  },
  "27": {
    "inputs": {
      "backend": "inductor",
      "fullgraph": false,
      "mode": "default",
      "dynamic": false,
      "dynamo_cache_size_limit": 64,
      "compile_single_blocks": true,
      "compile_double_blocks": true
    },
    "class_type": "FramePackTorchCompileSettings",
    "_meta": {
      "title": "Torch Compile Settings"
    }
  },
  "33": {
    "inputs": {
      "tile_size": 256,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "samples": ["39", 0],
      "vae": ["12", 0]
    },
    "class_type": "VAEDecodeTiled",
    "_meta": {
      "title": "VAE Decode (Tiled)"
    }
  },
  "39": {
    "inputs": {
      "steps": 30,
      "use_teacache": true,
      "teacache_rel_l1_thresh": 0.15,
      "cfg": 1,
      "guidance_scale": 10,
      "shift": 1.0000000000000002,
      "seed": 213738928831014,
      "latent_window_size": 9,
      "total_second_length": 5,
      "gpu_memory_preservation": 6,
      "sampler": "unipc_bh1",
      "denoise_strength": 1,
      "keyframe_weight": 1.5,
      "model": ["52", 0],
      "positive": ["47", 0],
      "negative": ["15", 0],
      "image_embeds": ["17", 0],
      "start_latent": ["20", 0]
    },
    "class_type": "FramePackSampler",
    "_meta": {
      "title": "FramePackSampler"
    }
  },
  "44": {
    "inputs": {
      "image": ["33", 0]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "47": {
    "inputs": {
      "text": "robot battle on the table.",
      "speak_and_recognation": {
        "__value__": [false, true]
      },
      "clip": ["13", 0]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "48": {
    "inputs": {
      "image": ["50", 0]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "50": {
    "inputs": {
      "width": ["51", 0],
      "height": ["51", 1],
      "interpolation": "lanczos",
      "method": "fill / crop",
      "condition": "always",
      "multiple_of": 0,
      "image": ["19", 0]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "51": {
    "inputs": {
      "base_resolution": 640,
      "image": ["19", 0]
    },
    "class_type": "FramePackFindNearestBucket",
    "_meta": {
      "title": "Find Nearest Bucket"
    }
  },
  "52": {
    "inputs": {
      "model": "hyvid\\FramePackI2V_HY_fp8_e4m3fn.safetensors",
      "base_precision": "bf16",
      "quantization": "fp8_e4m3fn",
      "attention_mode": "sdpa"
    },
    "class_type": "LoadFramePackModel",
    "_meta": {
      "title": "Load FramePackModel"
    }
  },
  "54": {
    "inputs": {
      "model": "lllyasviel/FramePackI2V_HY",
      "base_precision": "bf16",
      "quantization": "disabled",
      "attention_mode": "sdpa"
    },
    "class_type": "DownloadAndLoadFramePackModel",
    "_meta": {
      "title": "(Down)Load FramePackModel"
    }
  }
}
